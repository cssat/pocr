% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_portal_app_data.R
\name{get_portal_app_data}
\alias{get_portal_app_data}
\title{Get current data for Data Portal products with R generated data.}
\usage{
get_portal_app_data(target_apps = "all", excluded_apps = NULL,
  annie_connection = "annie", poc_connection = "POC")
}
\arguments{
\item{target_apps}{A string vector of application names to update. The names
match the pocdata repo names on GitHub. Defaults to "all" which updates
all supported applications.}

\item{excluded_apps}{A string vector of application names to avoid updating. 
Useful if you want to update most - but not all - applications. Defaults to 
NULL.}

\item{annie_connection}{An active RODBC connection to the "test_annie" MySQL
server or a character string that can be passed to 
\code{RODBC::odbcConnect()} to create an active RODBC connection to that 
server.}

\item{poc_connection}{An active RODBC connection to the "POC" SQL server
or a character string that can be passed to \code{RODBC::odbcConnect()} to 
create an active RODBC connection to that server.}
}
\description{
Most if not all Data Portal applications are dependent upon datasets 
tailored to each application's needs. 

It is the policy of the Data Portal team that data for such data-dependent 
applications must be generated either as part of Data Portal SQL loading or
by R processes defined in the \code{pocr} package.

This is the wrapper that generates current data for Data Portal products 
using R generated data. It is intended to be the first stage of the 
data update process for these products.

The user specifies which applications should receive a data update (the 
function defaults to updating all supported applications) and the wrapper
performs the necessary steps to:
\enumerate{
 \item Prepare data sources
 \item Gather updated data
 \item Process updated data to application specifications
 \item Write processed data to a local directory, named after the repo
}

The steps are performed application-by-application, with each application
having its own wrapper and suite of functions to handle its specific needs.

On successful completion, the user should manually inspect the generated
data. If it appears correct, the data should then be manually integrated
into each application's repo.
}
